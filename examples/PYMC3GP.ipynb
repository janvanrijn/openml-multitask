{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/janvanrijn/projects/openml-python')\n",
    "sys.path.append('/home/janvanrijn/projects/openml-python-contrib')\n",
    "sys.path.append('/home/janvanrijn/projects/pymc3')\n",
    "\n",
    "import arff\n",
    "import openmlcontrib\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import theano.tensor as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns = ['svc__gamma']\n",
    "y_column = 'predictive_accuracy'\n",
    "\n",
    "with open('/home/janvanrijn/projects/openml-multitask/data/svm-sklearn-bot.arff', 'r') as fp:\n",
    "    dataset = arff.load(fp)\n",
    "dataset = openmlcontrib.meta.arff_to_dataframe(dataset)\n",
    "dataset = dataset[dataset['task_id'] == 6]\n",
    "dataset = dataset[dataset['svc__kernel'] == 'rbf']\n",
    "\n",
    "X = np.array(dataset[x_columns].values, dtype=np.float)\n",
    "y = np.array(dataset[y_column].values, dtype=np.float)\n",
    "train_size = 200\n",
    "\n",
    "\n",
    "X_tr = X[:train_size]\n",
    "X_te = X[train_size:]\n",
    "\n",
    "y_tr = y[:train_size]\n",
    "y_te = y[train_size:]\n",
    "\n",
    "print(X_tr)\n",
    "\n",
    "n_dims = X_tr.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def warp_func(x, *args):\n",
    "#     n_dims = args[0]\n",
    "#     beta_dist = pm.distributions.continuous.Beta('beta_dist', args[1], args[2])\n",
    "#     return beta_dist.logp(x)\n",
    "\n",
    "with pm.Model() as marginal_gp_model:\n",
    "    # Specify the covariance function.\n",
    "    length_scales = []\n",
    "    alpha_parameters = []\n",
    "    beta_parameters = []\n",
    "    for i in range(n_dims):\n",
    "#         alpha = pm.distributions.continuous.Lognormal('a%d' % i, 0, 0.75)\n",
    "#         alpha_parameters.append(alpha)\n",
    "#         beta = pm.distributions.continuous.Lognormal('b%d' % i, 0, 0.75)\n",
    "#         beta_parameters.append(beta)\n",
    "#         length_scale = pm.distributions.continuous.Uniform('l%d' % i, 0, 10)\n",
    "#         length_scales.append(length_scale)\n",
    "        length_scales.append(1.0)\n",
    "    \n",
    "    cov_unwarped = pm.gp.cov.ExpQuad(n_dims, ls=length_scales)\n",
    "    # cov = pm.gp.cov.WarpedInput(n_dims, warp_func=warp_func, args=tuple([n_dims] + alpha_parameters + beta_parameters), cov_func=cov_unwarped)\n",
    "\n",
    "    # Specify the GP.  The default mean function is `Zero`.\n",
    "    gp = pm.gp.Marginal(cov_func=cov_unwarped)\n",
    "\n",
    "    # The scale of the white noise term can be provided,\n",
    "    sigma = pm.HalfCauchy(\"sigma\", beta=5)\n",
    "    y_ = gp.marginal_likelihood(\"y\", X=X_tr, y=y_tr, noise=sigma)\n",
    "    trace = pm.sample(2000, progressbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, var = gp.predict(X_te)\n",
    "\n",
    "scipy.stats.spearmanr(mu, y_te)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
